# USAGE: python sera/main.py --config-name config_specialize_sweb stage=pipeline name=test

# TODO: Move as much as can to defaults so this can be as slim as possible

defaults:
  - sera
  - _self_

name: specialize_existing
experiment_dir: ./experiments
sweagent_cfgs:
  - e2e
  - qwen

generate:
  fns_per_repo: 5000
  insts_per_fn: 1
  existing_repos:
    - org_name: sqlfluff # Instance id is not needed for swesmith because there is one container per repository.
      last_name: sqlfluff 
      source: swesmith 
    - org_name: sqlfluff # Instance id is not needed for swesmith because there is one container per repository.
      last_name: sqlfluff 
      source: swesmith 
    - org_name: sqlfluff # Instance id is not needed for swesmith because there is one container per repository.
      last_name: sqlfluff 
      source: swesmith 
    - org_name: sqlfluff # Instance id is not needed for swesmith because there is one container per repository.
      last_name: sqlfluff 
      source: swesmith 
    - org_name: sqlfluff # Instance id is not needed for swesmith because there is one container per repository.
      last_name: sqlfluff 
      source: swesmith 
    - org_name: sqlfluff # Instance id is not needed for swesmith because there is one container per repository.
      last_name: sqlfluff 
      source: swesmith 
    - org_name: sqlfluff # Instance id is not needed for swesmith because there is one container per repository.
      last_name: sqlfluff 
      source: swesmith 
  repo_parent_dir: ./repos

distill:
  shard: 0 # Can go 0-5 because there are six model instances
  models:
  - model: openai/GLM-4.5-Air
    url: # YOUR SERVER URL
  - model: openai/GLM-4.5-Air
    url: # YOUR SERVER URL
  - model: openai/GLM-4.5-Air
    url: # YOUR SERVER URL
  - model: openai/GLM-4.5-Air
    url: # YOUR SERVER URL
  - model: openai/GLM-4.5-Air
    url: # YOUR SERVER URL
  - model: openai/GLM-4.5-Air
    url: # YOUR SERVER URL
  stage_one_config_name: e2e
  stage_two_config_name: qwen
  sweagent_wrapper_config:
    num_workers: 24

postprocess:
  tool_call_format: hermes
  add_think: false
  add_train_key: true
  enforce_submit: true
  reformat_assistant_message: keep_only_think # With GLM 4.5 Air, we only keep the <think> portion to train on

eval:
  compare_patch_threshold: 0.5
